# Naïve and Robust: Class-Conditional Independence in Human Classification Learning

### Contributing Authors
Jana B. Jarecki, Björn Meder, Jonathan D. Nelson

### Dates
Paper published in 2017, very early insights in 2013.

### Abstract
Humans excel in categorization. Yet from a computational standpoint, learn-ing a novel probabilistic classification task involves severe computational challenges. The present paper investigates one way to address these chal-lenges: assuming class-conditional independence of features. This feature in-dependence assumption simplifies the inference problem, allows for informed inferences about novel feature combinations, and performs robustly across different statistical environments. We designed a new Bayesian classification learning model (the dependence-independence structure and category learn-ing model, DISC-LM) that incorporates varying degrees of prior belief in class-conditional independence, learns whether or not independence holds, and adapts its behavior accordingly. Theoretical results from two simulation studies demonstrate that classification behavior can appear to start simple, yet adapt effectively to unexpected task structures. Two experiments — de-signed using optimal experimental design principles — were conducted with human learners. Classification decisions of the majority of participants were best accounted for by a version of the model with very high initial prior belief in class-conditional independence, before adapting to the true envi-ronmental structure. Class-conditional independence may be a strong and useful default assumption in category learning tasks. Categorization—grouping objects into classes and identifying class membership—is a fundamental cognitive ability. From a computational perspective, category learning poses formidable challenges, yet humans excel at it. Cognitive science has investigated how hu-mans induce category structures, which representations they acquire, and which models CLASS-CONDITIONAL INDEPENDENCE 2 account for learning and generalization. A number of studies have asked whether people transition between different strategies during categorization learning, one insight from this work is that people start with simple strategies before progressing to more computa-tionally intense strategies. Johansen and Palmeri (2002) found that people initially apply uni-dimensional categorization rules (i.e., make classification decisions based on a single feature) and adopt more complex rules (i.e., a similarity-based strategy using multiple fea-tures) only if necessary. J. D. Smith and Minda (1998) observed that early in learning people tended to use a simple prototype-based strategy and only later shifted to a computationally more demanding exemplar-based strategy (but see Nosofsky & Zaki, 2002, for an alter-native interpretation). These findings suggest that people transition from computationally simple to more complex strategies. One benefit of starting simple is computational efficiency. As long as the initial simple rule gives good enough performance, a computationally more intense strategy need not be invoked. The performance of strategies also depends on the environmental structure (e.g., linearly vs. nonlinearly separable environments; Blair & Homa, 2001; Medin & Schwa-nenflugel, 1981). The environmental structure, however, is unknown at the beginning of learning. One important question for a simple strategy is whether it performs robustly across different environments. How can a strategy appear simple, and yet also be robust, and perform well in situations with unexpected environmental structures? Robust perfor-mance is especially important if the potential task structures are numerous and complex.

### Publications
* Jarecki, J. B., Meder, B., & Nelson, J. D. (2013). The Assumption of Class-Conditional Independence in Category Learning. In M. Knauff, M. Pauen, N. Sebanz, & I. Wachsmuth (Eds.), Proceedings of the 35th Annual Conference of the Cognitive Science Society (pp. 2650–2655). Cognitive Science Society. https://mindmodeling.org/cogsci2013/papers/0478/index.html
* Jarecki, J. B., Meder, B., & Nelson, J. D. (2017). Naïve and Robust: Class-Conditional Independence in Human Classification Learning. Cognitive Science, 42(1), 4–42. https://doi.org/10.1111/cogs.12496

### Open Data
2 Open-data datasets, 4 simulation studies

### Machine-Learning Models
1 new nodel based on Naive Bayes

### Funding
Max-Planck-Institute for Human Development, Berlin, and in part by grants NE 1713/1-2 to JDN, and ME 3717/2-2 to BM, from the Deutsche Forschungsgemeinschaft (DFG) as part of the priority program “New Frame- works of Rationality” (SPP 1516).

### Notes
None.
